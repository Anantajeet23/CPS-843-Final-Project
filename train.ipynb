{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "# Training Script for U-Net / U-Net++ / Attention U-Net / FCN / GTAM Models ON UDIAT\n",
    "# ===================================================================================\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Base models\n",
    "from unet import UNET\n",
    "from unetpp import UNETPP\n",
    "from att_unet import AttentionUNet\n",
    "from torchvision.models.segmentation import fcn_resnet50\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "\n",
    "# GTAM variants\n",
    "from unet_gtam import UNET_GTAM\n",
    "from unetpp_gtam import UNETPP_GTAM\n",
    "from att_unet_gtam import AttentionUNet_GTAM\n",
    "from fcn_resnet50_gtam import FCN_ResNet50_GTAM\n",
    "from DeepLabV3_gtam import DeepLabV3_ResNet50_GTAM\n",
    "\n",
    "from dataset_UDIAT import UDIATDataset\n",
    "from utils import train_fn, validate_fn, save_checkpoint, save_predictions, train_fn_resnet , validate_fn_resnet,save_predictions_resnet\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# CONFIGURATION\n",
    "# ==============================================================\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 60\n",
    "NUM_WORKERS = 2\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "PIN_MEMORY = True\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "IN_CHANNELS = 1\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# MODEL FLAGS — ONLY ONE SHOULD BE TRUE\n",
    "# ==============================================================\n",
    "\n",
    "Train_UNet = False\n",
    "Train_UNetPP = False\n",
    "Train_AttentionUNet = False\n",
    "Train_FCN_ResNet50 = False\n",
    "Train_DeepLabV3 = False\n",
    "\n",
    "Train_UNET_GTAM = False\n",
    "Train_UNetPP_GTAM = False\n",
    "Train_AttentionUNet_GTAM = False\n",
    "Train_FCN_ResNet50_GTAM = False\n",
    "Train_DeepLabV3_ResNet50_GTAM = False\n",
    "\n",
    "# ==============================================================\n",
    "# SET OUTPUT PATHS BASED ON MODEL TYPE\n",
    "# ==============================================================\n",
    "\n",
    "def set_paths(model_name, is_gtam=False):\n",
    "    if is_gtam:\n",
    "        base_best = \"Best_UDIAT_GTAM\"\n",
    "        base_ckpt = \"Checkpoints_UDIAT_GTAM\"\n",
    "        base_out = \"Outputs_UDIAT_GTAM\"\n",
    "    else:\n",
    "        base_best = \"Best_UDIAT\"\n",
    "        base_ckpt = \"Checkpoints_UDIAT\"\n",
    "        base_out = \"Outputs_UDIAT\"\n",
    "\n",
    "    best_path = f\"{base_best}/{model_name}_best.pth\"\n",
    "    ckpt_path = f\"{base_ckpt}/{model_name}_checkpoint.pth\"\n",
    "    out_path = f\"{base_out}/{model_name}_outputs\"\n",
    "\n",
    "    os.makedirs(base_best, exist_ok=True)\n",
    "    os.makedirs(base_ckpt, exist_ok=True)\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "    return best_path, ckpt_path, out_path\n",
    "\n",
    "\n",
    "\n",
    "def set_all_flags_false():\n",
    "    global Train_UNet, Train_UNetPP, Train_AttentionUNet\n",
    "    global Train_UNET_GTAM, Train_UNetPP_GTAM, Train_AttentionUNet_GTAM, IS_GTAM\n",
    "    global Train_FCN_ResNet50, Train_DeepLabV3,Train_DeepLabV3_ResNet50_GTAM\n",
    "\n",
    "    Train_UNet = False\n",
    "    Train_UNetPP = False\n",
    "    Train_AttentionUNet = False\n",
    "    Train_UNET_GTAM = False\n",
    "    Train_UnetPP_GTAM = False\n",
    "    Train_AttentionUNet_GTAM = False\n",
    "    Train_FCN_ResNet50 = False\n",
    "    Train_FCN_ResNet50_GTAM = False\n",
    "    Train_DeepLabV3 = False\n",
    "    Train_DeepLabV3_ResNet50_GTAM = False\n",
    "    IS_GTAM = False\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_IMG_DIR = \"UDIAT_Data/train/images\"\n",
    "TRAIN_MASK_DIR = \"UDIAT_Data/train/masks\"\n",
    "VAL_IMG_DIR = \"UDIAT_Data/validation/images\"\n",
    "VAL_MASK_DIR = \"UDIAT_Data/validation/masks\"\n",
    "\n",
    "# MAIN TRAINING\n",
    "\n",
    "def main():\n",
    "\n",
    "    #  Albumentations Augmentations \n",
    "    if MODEL_NAME in [\"FCN_ResNet50\", \"DeepLabV3\", \"FCN_ResNet50_GTAM\",\"DeepLabV3_ResNet50_GTAM\"]:\n",
    "        # convert 1-channel → 3-channel \n",
    "        train_transform = A.Compose([\n",
    "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.Rotate(limit=35, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.1),\n",
    "            A.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0], max_pixel_value=255.0),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "        val_transform = A.Compose([\n",
    "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0], max_pixel_value=255.0),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    else:\n",
    "        train_transform = A.Compose([\n",
    "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.Rotate(limit=35, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.1),\n",
    "            A.Normalize(mean=[0.0], std=[1.0], max_pixel_value=255.0),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "        val_transform = A.Compose([\n",
    "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.Normalize(mean=[0.0], std=[1.0], max_pixel_value=255.0),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "    #  DATASETS \n",
    "    train_ds = UDIATDataset(\n",
    "        image_dir=TRAIN_IMG_DIR,\n",
    "        mask_dir=TRAIN_MASK_DIR,\n",
    "        transform=train_transform,\n",
    "    )\n",
    "    val_ds = UDIATDataset(\n",
    "        image_dir=VAL_IMG_DIR,\n",
    "        mask_dir=VAL_MASK_DIR,\n",
    "        transform=val_transform,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    # ---------------- Model Selection ----------------\n",
    "    print(f\"\\nTraining model: {MODEL_NAME}\\n\")\n",
    "\n",
    "    if MODEL_NAME == \"UNet_GTAM\":\n",
    "        model = UNET_GTAM(IN_CHANNELS, NUM_CLASSES).to(DEVICE)\n",
    "    elif MODEL_NAME == \"UNetPP\":\n",
    "        model = UNETPP(IN_CHANNELS, NUM_CLASSES).to(DEVICE)\n",
    "    elif MODEL_NAME == \"UNetPP_GTAM\":\n",
    "        model = UNETPP_GTAM(IN_CHANNELS, NUM_CLASSES).to(DEVICE)\n",
    "    elif MODEL_NAME == \"FCN_ResNet50_GTAM\":\n",
    "        model = FCN_ResNet50_GTAM(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    elif MODEL_NAME == \"AttentionUNet\":\n",
    "        model = AttentionUNet(IN_CHANNELS, NUM_CLASSES).to(DEVICE)\n",
    "    elif MODEL_NAME == \"AttentionUNet_GTAM\":\n",
    "        model = AttentionUNet_GTAM(IN_CHANNELS, NUM_CLASSES).to(DEVICE)\n",
    "    elif MODEL_NAME == \"FCN_ResNet50\":\n",
    "        model = fcn_resnet50(weights=None, weights_backbone=None)\n",
    "        model.classifier[4] = nn.Conv2d(512, NUM_CLASSES, kernel_size=1)\n",
    "        model = model.to(DEVICE)\n",
    "    elif MODEL_NAME == \"DeepLabV3\":\n",
    "        model = deeplabv3_resnet50(weights=None, weights_backbone=None)\n",
    "        model.classifier[-1] = nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
    "        model = model.to(DEVICE)\n",
    "    elif MODEL_NAME == \"DeepLabV3_ResNet50_GTAM\":\n",
    "        model = DeepLabV3_ResNet50_GTAM(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    else:\n",
    "        model = UNET(IN_CHANNELS, NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "    \n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    \n",
    "    #  TRAINING LOOP \n",
    "    patience = 4\n",
    "    patience_counter = 0\n",
    "    best_val_dice = -1.0\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "\n",
    "        if MODEL_NAME in [\"FCN_ResNet50\", \"DeepLabV3\", \"FCN_ResNet50_GTAM\",\"DeepLabV3_ResNet50_GTAM\"]:\n",
    "            train_loss, train_dice = train_fn_resnet(\n",
    "                train_loader, model, optimizer, loss_fn, DEVICE, NUM_CLASSES\n",
    "            )\n",
    "        else:\n",
    "            train_loss, train_dice = train_fn(\n",
    "                train_loader, model, optimizer, loss_fn, DEVICE, NUM_CLASSES\n",
    "            )\n",
    "\n",
    "        if MODEL_NAME in [\"FCN_ResNet50\", \"DeepLabV3\", \"FCN_ResNet50_GTAM\",\"DeepLabV3_ResNet50_GTAM\"]:\n",
    "            val_loss, val_dice = validate_fn_resnet(\n",
    "                val_loader, model, loss_fn, DEVICE, NUM_CLASSES\n",
    "            )\n",
    "        else:\n",
    "            val_loss, val_dice = validate_fn(\n",
    "                val_loader, model, loss_fn, DEVICE, NUM_CLASSES\n",
    "            )\n",
    "\n",
    "        print(f\"Epoch {epoch:03d} | \"\n",
    "              f\"train_loss: {train_loss:.4f}  train_dice: {train_dice:.4f} | \"\n",
    "              f\"val_loss: {val_loss:.4f}  val_dice: {val_dice:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_dice > best_val_dice:\n",
    "            best_val_dice = val_dice\n",
    "            patience_counter = 0\n",
    "            save_checkpoint(model, optimizer, epoch, path=best)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered at epoch {epoch}.\")\n",
    "            break\n",
    "\n",
    "        # Occasional rolling checkpoint\n",
    "        if epoch % 5 == 0:\n",
    "            save_checkpoint(model, optimizer, epoch, path=checkpt)\n",
    "    \n",
    "    if MODEL_NAME in [\"FCN_ResNet50\", \"DeepLabV3\" ,\"FCN_ResNet50_GTAM\",\"DeepLabV3_ResNet50_GTAM\"]:\n",
    "        save_predictions_resnet(model, val_loader, DEVICE, folder=final_folder)\n",
    "    else:\n",
    "        save_predictions(model, val_loader, DEVICE, folder=final_folder)\n",
    "    print(\"Saved predicted example masks\")\n",
    "\n",
    "\n",
    "def run_training():\n",
    "    main() \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    models_to_train = [\n",
    "        # \"UNetPP\",\n",
    "        \"DeepLabV3_ResNet50_GTAM\",\n",
    "        # \"DeepLabV3\",\n",
    "        # \"UNet\",\n",
    "        # \"AttentionUNet\",\n",
    "        # \"UNet_GTAM\",\n",
    "        # \"UNetPP_GTAM\",\n",
    "        # \"AttentionUNet_GTAM\",\n",
    "        \n",
    "    ]\n",
    "\n",
    "    for model in models_to_train:\n",
    "        print(\"\\n========================================\")\n",
    "        print(f\"   TRAINING MODEL: {model}\")\n",
    "        print(\"========================================\\n\")\n",
    "\n",
    "        # turn all switches off\n",
    "        set_all_flags_false()\n",
    "\n",
    "        MODEL_NAME = model\n",
    "\n",
    "       \n",
    "        # turn on only the required one\n",
    "        if model == \"UNet\":\n",
    "            Train_UNet = True\n",
    "        elif model == \"UNetPP\":\n",
    "            Train_UNetPP = True\n",
    "        elif model == \"AttentionUNet\":\n",
    "            Train_AttentionUNet = True\n",
    "        elif model == \"UNet_GTAM\":\n",
    "            Train_UNET_GTAM = True\n",
    "            IS_GTAM = True\n",
    "        elif model == \"UNetPP_GTAM\":\n",
    "            Train_UnetPP_GTAM = True\n",
    "            IS_GTAM = True\n",
    "        elif model == \"AttentionUNet_GTAM\":\n",
    "            Train_AttentionUNet_GTAM = True\n",
    "            IS_GTAM = True\n",
    "        elif model == \"DeepLabV3\":\n",
    "            Train_DeepLabV3 = True\n",
    "        elif model == \"DeepLabV3_ResNet50_GTAM\":\n",
    "            Train_DeepLabV3_ResNet50_GTAM = True\n",
    "            IS_GTAM = True\n",
    "\n",
    "\n",
    "        best, checkpt, final_folder = set_paths(MODEL_NAME, is_gtam=IS_GTAM)\n",
    "\n",
    "        if MODEL_NAME in [\"FCN_ResNet50\", \"DeepLabV3\", \"FCN_ResNet50_GTAM\",\"DeepLabV3_ResNet50_GTAM\"]:\n",
    "            IN_CHANNELS = 3\n",
    "        else:\n",
    "            IN_CHANNELS = 1\n",
    "\n",
    "        # run training\n",
    "        run_training()\n",
    "\n",
    "        print(f\"\\n FINISHED TRAINING {model} \\n\")\n",
    "\n",
    "    print(\"\\n ALL MODELS TRAINED SUCCESSFULLY! \")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "# Training Script for U-Net / U-Net++ / Attention U-Net / FCN / GTAM Models ON BUSI\n",
    "# ==================================================================================\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Base models\n",
    "from unet import UNET\n",
    "from unetpp import UNETPP\n",
    "from att_unet import AttentionUNet\n",
    "from torchvision.models.segmentation import fcn_resnet50\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "\n",
    "# GTAM variants\n",
    "from unet_gtam import UNET_GTAM\n",
    "from unetpp_gtam import UNETPP_GTAM\n",
    "from att_unet_gtam import AttentionUNet_GTAM\n",
    "from fcn_resnet50_gtam import FCN_ResNet50_GTAM\n",
    "from DeepLabV3_gtam import DeepLabV3_ResNet50_GTAM\n",
    "\n",
    "from dataset_BUSI import BUSIDataset\n",
    "from utils import train_fn, validate_fn, save_checkpoint, save_predictions, train_fn_resnet , validate_fn_resnet,save_predictions_resnet\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# CONFIGURATION\n",
    "# ==============================================================\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 60\n",
    "NUM_WORKERS = 2\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "PIN_MEMORY = True\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "IN_CHANNELS = 1\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# MODEL FLAGS — ONLY ONE SHOULD BE TRUE\n",
    "# ==============================================================\n",
    "\n",
    "Train_UNet = False\n",
    "Train_UNetPP = False\n",
    "Train_AttentionUNet = False\n",
    "Train_FCN_ResNet50 = False\n",
    "Train_DeepLabV3 = False\n",
    "\n",
    "Train_UNET_GTAM = False\n",
    "Train_UNetPP_GTAM = False\n",
    "Train_AttentionUNet_GTAM = False\n",
    "Train_FCN_ResNet50_GTAM = False\n",
    "Train_DeepLabV3_ResNet50_GTAM = False\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# SET OUTPUT PATHS BASED ON MODEL TYPE\n",
    "# ==============================================================\n",
    "\n",
    "def set_paths(model_name, is_gtam=False):\n",
    "    if is_gtam:\n",
    "        base_best = \"BUSI/Best_BUSI_GTAM\"\n",
    "        base_ckpt = \"BUSI/Checkpoints_BUSI_GTAM\"\n",
    "        base_out = \"BUSI/Outputs_BUSI_GTAM\"\n",
    "    else:\n",
    "        base_best = \"BUSI/Best_BUSI\"\n",
    "        base_ckpt = \"BUSI/Checkpoints_BUSI\"\n",
    "        base_out = \"BUSI/Outputs_BUSI\"\n",
    "\n",
    "    best_path = f\"{base_best}/{model_name}_best.pth\"\n",
    "    ckpt_path = f\"{base_ckpt}/{model_name}_checkpoint.pth\"\n",
    "    out_path = f\"{base_out}/{model_name}_outputs\"\n",
    "\n",
    "    os.makedirs(base_best, exist_ok=True)\n",
    "    os.makedirs(base_ckpt, exist_ok=True)\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "    return best_path, ckpt_path, out_path\n",
    "\n",
    "\n",
    "\n",
    "def set_all_flags_false():\n",
    "    global Train_UNet, Train_UNetPP, Train_AttentionUNet\n",
    "    global Train_UNET_GTAM, Train_UNetPP_GTAM, Train_AttentionUNet_GTAM, IS_GTAM\n",
    "    global Train_FCN_ResNet50, Train_DeepLabV3,Train_DeepLabV3_ResNet50_GTAM\n",
    "\n",
    "    Train_UNet = False\n",
    "    Train_UNetPP = False\n",
    "    Train_AttentionUNet = False\n",
    "    Train_UNET_GTAM = False\n",
    "    Train_UnetPP_GTAM = False\n",
    "    Train_AttentionUNet_GTAM = False\n",
    "    Train_FCN_ResNet50 = False\n",
    "    Train_FCN_ResNet50_GTAM = False\n",
    "    Train_DeepLabV3 = False\n",
    "    Train_DeepLabV3_ResNet50_GTAM = False\n",
    "    IS_GTAM = False\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_IMG_DIR = \"BUSI/Data/train/images\"\n",
    "TRAIN_MASK_DIR = \"BUSI/Data/train/masks\"\n",
    "VAL_IMG_DIR = \"BUSI/Data/validation/images\"\n",
    "VAL_MASK_DIR = \"BUSI/Data/validation/masks\"\n",
    "\n",
    "# MAIN TRAINING\n",
    "\n",
    "def main():\n",
    "\n",
    "    #  Albumentations Augmentations \n",
    "    if MODEL_NAME in [\"FCN_ResNet50\", \"DeepLabV3\", \"FCN_ResNet50_GTAM\",\"DeepLabV3_ResNet50_GTAM\"]:\n",
    "        # convert 1-channel → 3-channel \n",
    "        train_transform = A.Compose([\n",
    "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.Rotate(limit=35, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.1),\n",
    "            A.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0], max_pixel_value=255.0),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "        val_transform = A.Compose([\n",
    "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0], max_pixel_value=255.0),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    else:\n",
    "        train_transform = A.Compose([\n",
    "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.Rotate(limit=35, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.1),\n",
    "            A.Normalize(mean=[0.0], std=[1.0], max_pixel_value=255.0),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "        val_transform = A.Compose([\n",
    "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.Normalize(mean=[0.0], std=[1.0], max_pixel_value=255.0),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "    #  DATASETS \n",
    "    train_ds = BUSIDataset(\n",
    "        image_dir=TRAIN_IMG_DIR,\n",
    "        mask_dir=TRAIN_MASK_DIR,\n",
    "        transform=train_transform,\n",
    "    )\n",
    "    val_ds = BUSIDataset(\n",
    "        image_dir=VAL_IMG_DIR,\n",
    "        mask_dir=VAL_MASK_DIR,\n",
    "        transform=val_transform,\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    # ---------------- Model Selection ----------------\n",
    "    print(f\"\\nTraining model: {MODEL_NAME}\\n\")\n",
    "\n",
    "    if MODEL_NAME == \"UNet_GTAM\":\n",
    "        model = UNET_GTAM(IN_CHANNELS, NUM_CLASSES).to(DEVICE)\n",
    "    elif MODEL_NAME == \"UNetPP\":\n",
    "        model = UNETPP(IN_CHANNELS, NUM_CLASSES).to(DEVICE)\n",
    "    elif MODEL_NAME == \"UNetPP_GTAM\":\n",
    "        model = UNETPP_GTAM(IN_CHANNELS, NUM_CLASSES).to(DEVICE)\n",
    "    elif MODEL_NAME == \"FCN_ResNet50_GTAM\":\n",
    "        model = FCN_ResNet50_GTAM(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    elif MODEL_NAME == \"AttentionUNet\":\n",
    "        model = AttentionUNet(IN_CHANNELS, NUM_CLASSES).to(DEVICE)\n",
    "    elif MODEL_NAME == \"AttentionUNet_GTAM\":\n",
    "        model = AttentionUNet_GTAM(IN_CHANNELS, NUM_CLASSES).to(DEVICE)\n",
    "    elif MODEL_NAME == \"FCN_ResNet50\":\n",
    "        model = fcn_resnet50(weights=None, weights_backbone=None)\n",
    "        model.classifier[4] = nn.Conv2d(512, NUM_CLASSES, kernel_size=1)\n",
    "        model = model.to(DEVICE)\n",
    "    elif MODEL_NAME == \"DeepLabV3\":\n",
    "        model = deeplabv3_resnet50(weights=None, weights_backbone=None)\n",
    "        model.classifier[-1] = nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
    "        model = model.to(DEVICE)\n",
    "    elif MODEL_NAME == \"DeepLabV3_ResNet50_GTAM\":\n",
    "        model = DeepLabV3_ResNet50_GTAM(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    else:\n",
    "        model = UNET(IN_CHANNELS, NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "    \n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    \n",
    "    #  TRAINING LOOP \n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    best_val_dice = -1.0\n",
    "\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "\n",
    "        if MODEL_NAME in [\"FCN_ResNet50\", \"DeepLabV3\", \"FCN_ResNet50_GTAM\",\"DeepLabV3_ResNet50_GTAM\"]:\n",
    "            train_loss, train_dice = train_fn_resnet(\n",
    "                train_loader, model, optimizer, loss_fn, DEVICE, NUM_CLASSES\n",
    "            )\n",
    "        else:\n",
    "            train_loss, train_dice = train_fn(\n",
    "                train_loader, model, optimizer, loss_fn, DEVICE, NUM_CLASSES\n",
    "            )\n",
    "\n",
    "        if MODEL_NAME in [\"FCN_ResNet50\", \"DeepLabV3\", \"FCN_ResNet50_GTAM\",\"DeepLabV3_ResNet50_GTAM\"]:\n",
    "            val_loss, val_dice = validate_fn_resnet(\n",
    "                val_loader, model, loss_fn, DEVICE, NUM_CLASSES\n",
    "            )\n",
    "        else:\n",
    "            val_loss, val_dice = validate_fn(\n",
    "                val_loader, model, loss_fn, DEVICE, NUM_CLASSES\n",
    "            )\n",
    "\n",
    "        print(f\"Epoch {epoch:03d} | \"\n",
    "              f\"train_loss: {train_loss:.4f}  train_dice: {train_dice:.4f} | \"\n",
    "              f\"val_loss: {val_loss:.4f}  val_dice: {val_dice:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_dice > best_val_dice:\n",
    "            best_val_dice = val_dice\n",
    "            patience_counter = 0\n",
    "            save_checkpoint(model, optimizer, epoch, path=best)\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping triggered at epoch {epoch}.\")\n",
    "            break\n",
    "\n",
    "        # Occasional rolling checkpoint\n",
    "        if epoch % 5 == 0:\n",
    "            save_checkpoint(model, optimizer, epoch, path=checkpt)\n",
    "    \n",
    "    if MODEL_NAME in [\"FCN_ResNet50\", \"DeepLabV3\" ,\"FCN_ResNet50_GTAM\",\"DeepLabV3_ResNet50_GTAM\"]:\n",
    "        save_predictions_resnet(model, val_loader, DEVICE, folder=final_folder)\n",
    "    else:\n",
    "        save_predictions(model, val_loader, DEVICE, folder=final_folder)\n",
    "    print(\"Saved predicted example masks\")\n",
    "\n",
    "\n",
    "def run_training():\n",
    "    main() \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    models_to_train = [\n",
    "        # \"UNetPP\",\n",
    "        \"DeepLabV3_ResNet50_GTAM\",\n",
    "        # \"DeepLabV3\",\n",
    "        # \"UNet\",\n",
    "        # \"AttentionUNet\",\n",
    "        # \"UNet_GTAM\",\n",
    "        # \"UNetPP_GTAM\",\n",
    "        # \"AttentionUNet_GTAM\",\n",
    "        \n",
    "    ]\n",
    "\n",
    "    for model in models_to_train:\n",
    "        print(\"\\n========================================\")\n",
    "        print(f\"   TRAINING MODEL: {model} on BUSI\")\n",
    "        print(\"========================================\\n\")\n",
    "\n",
    "        # turn all switches off\n",
    "        set_all_flags_false()\n",
    "\n",
    "        MODEL_NAME = model\n",
    "\n",
    "       \n",
    "        # turn on only the required one\n",
    "        if model == \"UNet\":\n",
    "            Train_UNet = True\n",
    "        elif model == \"UNetPP\":\n",
    "            Train_UNetPP = True\n",
    "        elif model == \"AttentionUNet\":\n",
    "            Train_AttentionUNet = True\n",
    "        elif model == \"UNet_GTAM\":\n",
    "            Train_UNET_GTAM = True\n",
    "            IS_GTAM = True\n",
    "        elif model == \"UNetPP_GTAM\":\n",
    "            Train_UnetPP_GTAM = True\n",
    "            IS_GTAM = True\n",
    "        elif model == \"AttentionUNet_GTAM\":\n",
    "            Train_AttentionUNet_GTAM = True\n",
    "            IS_GTAM = True\n",
    "        elif model == \"DeepLabV3\":\n",
    "            Train_DeepLabV3 = True\n",
    "        elif model == \"DeepLabV3_ResNet50_GTAM\":\n",
    "            Train_DeepLabV3_ResNet50_GTAM = True\n",
    "            IS_GTAM = True\n",
    "            \n",
    "        best, checkpt, final_folder = set_paths(MODEL_NAME, is_gtam=IS_GTAM)\n",
    "\n",
    "        if MODEL_NAME in [\"FCN_ResNet50\", \"DeepLabV3\", \"FCN_ResNet50_GTAM\",\"DeepLabV3_ResNet50_GTAM\"]:\n",
    "            IN_CHANNELS = 3\n",
    "        else:\n",
    "            IN_CHANNELS = 1\n",
    "\n",
    "        # run training\n",
    "        run_training()\n",
    "\n",
    "        print(f\"\\n FINISHED TRAINING {model} \\n\")\n",
    "\n",
    "    print(\"\\n ALL MODELS TRAINED SUCCESSFULLY! \")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_gtam_heatmaps\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt   \n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from dataset_BUSI import BUSIDataset    \n",
    "from att_unet_gtam import AttentionUNet_GTAM\n",
    "from unetpp_gtam import UNETPP_GTAM\n",
    "from gtam import GaborTAM\n",
    "from metrics import compute_metrics     \n",
    "\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "TEST_IMG_DIR = \"UDIAT_Data/test/images\"        \n",
    "TEST_MASK_DIR = \"UDIAT_Data/test/masks\"\n",
    "\n",
    "CKPT_PATH = \"Best_UDIAT_GTAM/UNetPP_GTAM_best.pth\"   \n",
    "OUT_FOLDER = \"GTAM_Heatmaps_UDIAT\"                 \n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Albumentations transform\n",
    "# -----------------------------\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=256, width=256),\n",
    "        A.Normalize(mean=[0.0], std=[1.0], max_pixel_value=255.0),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_ds = UDIATDataset(TEST_IMG_DIR, TEST_MASK_DIR, transform=test_transform)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: find first GaborTAM\n",
    "# -----------------------------\n",
    "def find_gtam_module(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, GaborTAM):\n",
    "            return m\n",
    "    raise RuntimeError(\"No GaborTAM module found in model.\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load model + checkpoint\n",
    "# -----------------------------\n",
    "def load_gtam_model():\n",
    "    model = UNETPP_GTAM(1, 2).to(DEVICE)\n",
    "    ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    model.eval()\n",
    "    return model\n",
    " \n",
    "\n",
    "        \n",
    "# -----------------------------\n",
    "# Main visualization function\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def save_gtam_heatmaps():\n",
    "    os.makedirs(OUT_FOLDER, exist_ok=True)\n",
    "\n",
    "    model = load_gtam_model()\n",
    "    gtab = find_gtam_module(model)\n",
    "\n",
    "    print(f\"Found GTAM module: {gtab.__class__.__name__}\")\n",
    "    print(f\"Saving outputs to: {OUT_FOLDER}\")\n",
    "\n",
    "    for idx, (images, masks) in enumerate(test_loader):\n",
    "        images = images.to(DEVICE)          # (1,1,H,W)\n",
    "        masks = masks.long()                # (1,H,W) \n",
    "\n",
    "        # forward pass to generate logits + fill gtab.last_attn\n",
    "        logits = model(images)              # (1,2,H,W)\n",
    "\n",
    "        # prediction\n",
    "        probs = torch.softmax(logits, dim=1)[:, 1]       # (1,H,W)\n",
    "        preds = (probs > 0.5).float().cpu().numpy()[0]   # (H,W)\n",
    "\n",
    "        # GTAM attention map from module\n",
    "        attn = gtab.last_attn                    # (1,1,h,w)\n",
    "        if attn is None:\n",
    "            raise RuntimeError(\"GTAM last_attn is None. Did you forward through the module?\")\n",
    "\n",
    "        # upsample attention to image size\n",
    "        attn_up = F.interpolate(\n",
    "            attn, size=images.shape[-2:], mode=\"bilinear\", align_corners=False\n",
    "        )                                           # (1,1,H,W)\n",
    "        attn_up = attn_up.cpu().numpy()[0, 0]      # (H,W)\n",
    "\n",
    "        # normalize attention to [0,1]\n",
    "        attn_min, attn_max = attn_up.min(), attn_up.max()\n",
    "        if attn_max > attn_min:\n",
    "            attn_norm = (attn_up - attn_min) / (attn_max - attn_min)\n",
    "        else:\n",
    "            attn_norm = np.zeros_like(attn_up)\n",
    "\n",
    "        # ---------- COLOR HEATMAP ----------\n",
    "        # apply colormap (e.g. 'jet')\n",
    "        attn_color = plt.cm.jet(attn_norm)              # (H,W,4) RGBA\n",
    "        attn_color = (attn_color[..., :3] * 255).astype(np.uint8)  # (H,W,3) RGB\n",
    "\n",
    "        # ---------- ORIGINAL IMAGE (GRAY) ----------\n",
    "        img_np = images.cpu().numpy()[0, 0]        # (H,W)\n",
    "        img_min, img_max = img_np.min(), img_np.max()\n",
    "        if img_max > img_min:\n",
    "            img_norm = (img_np - img_min) / (img_max - img_min)\n",
    "        else:\n",
    "            img_norm = np.zeros_like(img_np)\n",
    "        img_uint8 = (img_norm * 255).astype(np.uint8)\n",
    "\n",
    "        # mask (0/1 → 0/255)\n",
    "        mask_np = masks.numpy()[0] * 255\n",
    "        mask_uint8 = mask_np.astype(np.uint8)\n",
    "\n",
    "        # pred (0/1 → 0/255)\n",
    "        pred_uint8 = (preds * 255).astype(np.uint8)\n",
    "\n",
    "        # ---------- OVERLAY (GRAY IMAGE + COLOR HEATMAP) ----------\n",
    "        img_rgb = np.stack([img_uint8, img_uint8, img_uint8], axis=-1)  # (H,W,3)\n",
    "        alpha = 0.5\n",
    "        overlay = (alpha * img_rgb + (1 - alpha) * attn_color).astype(np.uint8)\n",
    "\n",
    "        # ---------- SAVE ALL ----------\n",
    "        Image.fromarray(img_uint8, mode=\"L\").save(\n",
    "            os.path.join(OUT_FOLDER, f\"sample_{idx:03d}_image.png\")\n",
    "        )\n",
    "        Image.fromarray(mask_uint8, mode=\"L\").save(\n",
    "            os.path.join(OUT_FOLDER, f\"sample_{idx:03d}_mask.png\")\n",
    "        )\n",
    "        Image.fromarray(pred_uint8, mode=\"L\").save(\n",
    "            os.path.join(OUT_FOLDER, f\"sample_{idx:03d}_pred.png\")\n",
    "        )\n",
    "        # raw grayscale attention (optional)\n",
    "        attn_gray_uint8 = (attn_norm * 255).astype(np.uint8)\n",
    "        Image.fromarray(attn_gray_uint8, mode=\"L\").save(\n",
    "            os.path.join(OUT_FOLDER, f\"sample_{idx:03d}_gtam_gray.png\")\n",
    "        )\n",
    "        # color heatmap\n",
    "        Image.fromarray(attn_color).save(\n",
    "            os.path.join(OUT_FOLDER, f\"sample_{idx:03d}_gtam_color.png\")\n",
    "        )\n",
    "        # overlay\n",
    "        Image.fromarray(overlay).save(\n",
    "            os.path.join(OUT_FOLDER, f\"sample_{idx:03d}_overlay.png\")\n",
    "        )\n",
    "\n",
    "        if idx % 20 == 0:\n",
    "            print(f\"Saved heatmaps for sample {idx}\")\n",
    "\n",
    "    print(\"Done. Saved GTAM visualizations for all test images.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    save_gtam_heatmaps()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
